{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a077587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c53c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "\n",
    "def MCRMSE_SINGLE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    mcrmse_score = mean_squared_error(y_trues, y_preds, squared=False) # RMSE\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds, single=False):\n",
    "    if single:\n",
    "        mcrmse_score, scores = MCRMSE_SINGLE(y_trues, y_preds)\n",
    "    else:\n",
    "        mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2cd2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"../data/raw/summaries_train.csv\"\n",
    " \n",
    "\n",
    "csvs = [\n",
    "    \"../data/oofs/model236.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a7aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ee7181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_smoothing(predictions, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Apply post-processing smoothing to a set of predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - predictions: NumPy array containing the model's raw predictions.\n",
    "    - alpha: Smoothing parameter (0 <= alpha <= 1). Higher values increase smoothing.\n",
    "\n",
    "    Returns:\n",
    "    - smoothed_predictions: NumPy array with smoothed predictions.\n",
    "    \"\"\"\n",
    "    num_samples, num_columns = predictions.shape\n",
    "    \n",
    "    # Initialize an array to store smoothed predictions\n",
    "    smoothed_predictions = np.zeros_like(predictions)\n",
    "    \n",
    "    \n",
    "    # Apply smoothing to each column (prediction)\n",
    "    for col in range(num_columns):\n",
    "        column_predictions = predictions[:, col]\n",
    "        smoothed_predictions[:, col] = column_predictions * (1 - alpha) + alpha * column_predictions.mean()\n",
    "    \n",
    "    return smoothed_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2e1de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = []\n",
    "\n",
    "for csv in csvs:\n",
    "    df = pd.read_csv(csv)\n",
    "    df[['content', 'wording']] = apply_smoothing(df[['content', 'wording']].values, alpha=0.025)\n",
    "\n",
    "    ## post processing\n",
    "    df = df.loc[df.student_id.isin(train_df.student_id.values)].reset_index(drop=True)    \n",
    "    \n",
    "    merged_df = df.merge(\n",
    "        train_df,\n",
    "        left_on='student_id',\n",
    "        right_on='student_id',\n",
    "        how='outer',\n",
    "        suffixes=('_pred','_gt')\n",
    "    ) \n",
    "    \n",
    "    merged_df = merged_df.loc[merged_df.fold.isin([0,1,2,3])]    \n",
    "    oofs.append(merged_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14b844ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1, fold 0 0.4419974461268222 [0.3826441421407404, 0.501350750112904]\n",
      "model1, fold 1 0.5057045284198259 [0.4337077574708537, 0.5777012993687981]\n",
      "model1, fold 2 0.43217760493884116 [0.3944587569425775, 0.4698964529351048]\n",
      "model1, fold 3 0.5432992682438758 [0.46101865376780243, 0.625579882719949]\n",
      "model236.csv model1 0.4747572360399296 [0.4133297543496843, 0.5361847177301748]\n",
      "**************************************************\n",
      "0.4419974461268222 model1\n",
      "0.5057045284198259 model1\n",
      "0.43217760493884116 model1\n",
      "0.5432992682438758 model1\n"
     ]
    }
   ],
   "source": [
    "best_f0, best_f1, best_f2, best_f3 = 1, 1, 1, 1\n",
    "best_f0_exp, best_f1_exp, best_f2_exp, best_f3_exp = 1, 1, 1, 1\n",
    "\n",
    "\n",
    "for index, oof in enumerate(oofs):\n",
    "    true_labels_content = oof[['content_gt']].values\n",
    "    true_labels_wording = oof[['wording_gt']].values\n",
    "    \n",
    "    true_labels_oof = oof[['content_gt', 'wording_gt']].values\n",
    "    predictions_oof = oof[['content_pred', 'wording_pred']].values \n",
    "    \n",
    "    for fold in [0,1,2,3]:\n",
    "        oof1 = oof.loc[oof.fold == fold]\n",
    "        true_labels = oof1[['content_gt', 'wording_gt']].values\n",
    "        predictions = oof1[['content_pred', 'wording_pred']].values    \n",
    "        score, scores = get_score(true_labels, predictions)\n",
    "        print(f\"model{index+1}, fold {fold}\", score, scores)\n",
    "        if fold == 0 and score < best_f0:\n",
    "            best_f0 = score\n",
    "            best_f0_exp = index + 1\n",
    "        elif fold == 1 and score < best_f1:\n",
    "            best_f1 = score\n",
    "            best_f1_exp = index + 1\n",
    "        elif fold == 2 and score < best_f2:\n",
    "            best_f2 = score\n",
    "            best_f2_exp = index + 1\n",
    "        elif fold == 3 and score < best_f3:\n",
    "            best_f3 = score\n",
    "            best_f3_exp = index + 1\n",
    "            \n",
    "            \n",
    "    score, scores = get_score(true_labels_oof, predictions_oof)\n",
    "    print(csvs[index].split(\"/\")[-1], f\"model{index+1}\", score, scores)\n",
    "    print(\"*\"*50)\n",
    "    \n",
    "    \n",
    "print(best_f0, f\"model{best_f0_exp}\")\n",
    "print(best_f1, f\"model{best_f1_exp}\")\n",
    "print(best_f2, f\"model{best_f2_exp}\")\n",
    "print(best_f3, f\"model{best_f3_exp}\") # 0.47563110509395745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e69bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e39e3cc",
   "metadata": {},
   "source": [
    "### Optuna Weight Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb0781dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:49,933] A new study created in memory with name: no-name-ef521d64-6b0c-4fe6-a3be-d54cb3016850\n",
      "[I 2023-10-12 12:01:49,938] Trial 0 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8846156258427612}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,940] Trial 1 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5164597922916226}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,941] Trial 2 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4241199740897519}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,943] Trial 3 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4320749704975453}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,945] Trial 4 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3866896705570465}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,947] Trial 5 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7158342897000441}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,949] Trial 6 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6971001430401504}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,951] Trial 7 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6688945306030653}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,953] Trial 8 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4707975501699757}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,955] Trial 9 finished with value: 0.4747572360399296 and parameters: {'w1': 0.879349589638186}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,962] Trial 10 finished with value: 0.4747572360399296 and parameters: {'w1': 0.036303223303145504}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,969] Trial 11 finished with value: 0.4747572360399296 and parameters: {'w1': 0.948372717355945}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,976] Trial 12 finished with value: 0.4747572360399296 and parameters: {'w1': 0.944976368264901}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,982] Trial 13 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5894626348463765}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,988] Trial 14 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8206549203117337}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:49,994] Trial 15 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7947297233566775}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,001] Trial 16 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5676052133795177}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,008] Trial 17 finished with value: 0.4747572360399296 and parameters: {'w1': 0.946836971922492}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,015] Trial 18 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3003402459612527}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,020] Trial 19 finished with value: 0.4747572360399296 and parameters: {'w1': 0.798258896354922}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,026] Trial 20 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9998829094145372}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,033] Trial 21 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3142053306746972}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,040] Trial 22 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5626892614847437}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,047] Trial 23 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5347571912622515}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,054] Trial 24 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6442657420365194}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,061] Trial 25 finished with value: 0.4747572360399296 and parameters: {'w1': 0.48942396590854786}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,067] Trial 26 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7522085167643894}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,074] Trial 27 finished with value: 0.4747572360399296 and parameters: {'w1': 0.600057657890218}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,080] Trial 28 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8492173428010968}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,087] Trial 29 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4081091530009959}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,095] Trial 30 finished with value: 0.4747572360399296 and parameters: {'w1': 0.718246836073381}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,100] Trial 31 finished with value: 0.4747572360399296 and parameters: {'w1': 0.42637873444437513}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,107] Trial 32 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3367174084417289}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,115] Trial 33 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4768744525157943}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,122] Trial 34 finished with value: 0.4747572360399296 and parameters: {'w1': 0.24921611862197807}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,127] Trial 35 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6578498946793153}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,135] Trial 36 finished with value: 0.4747572360399296 and parameters: {'w1': 0.435413358870564}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,142] Trial 37 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5107388913941906}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,149] Trial 38 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3840549613631472}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,155] Trial 39 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5267029699948845}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,162] Trial 40 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7587777681525509}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,169] Trial 41 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4726239426352032}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,177] Trial 42 finished with value: 0.4747572360399296 and parameters: {'w1': 0.37248904064718213}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,184] Trial 43 finished with value: 0.4747572360399296 and parameters: {'w1': 0.24227547148087056}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,191] Trial 44 finished with value: 0.4747572360399296 and parameters: {'w1': 0.89160446764693}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,198] Trial 45 finished with value: 0.4747572360399296 and parameters: {'w1': 0.44425483780767294}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,205] Trial 46 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6187889043073297}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,212] Trial 47 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6802204218915293}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:50,219] Trial 48 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5627646625187428}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,226] Trial 49 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3588876982567428}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,233] Trial 50 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6214187858361596}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,240] Trial 51 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8731578871747775}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,248] Trial 52 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5286112264703438}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,255] Trial 53 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7310734026571893}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,261] Trial 54 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6984431820604529}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,268] Trial 55 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7825351087405076}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,274] Trial 56 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4105922791809448}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,282] Trial 57 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4608762888025711}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,289] Trial 58 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8061908181553736}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,296] Trial 59 finished with value: 0.4747572360399296 and parameters: {'w1': 0.49694361281718}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,304] Trial 60 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5944971946449936}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,311] Trial 61 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6910466868220899}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,317] Trial 62 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6386678725336055}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,325] Trial 63 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8366187736087881}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,332] Trial 64 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5663337487789086}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,339] Trial 65 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7695178382393788}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,347] Trial 66 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7291404821967051}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,354] Trial 67 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6726435433739142}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,361] Trial 68 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9174949383503044}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,369] Trial 69 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9790510606381906}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,375] Trial 70 finished with value: 0.4747572360399296 and parameters: {'w1': 0.45394777161377603}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,383] Trial 71 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8402736974679621}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,390] Trial 72 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7913593728186837}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,397] Trial 73 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6425187433073117}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,405] Trial 74 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7451712368260144}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,412] Trial 75 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7032445708201229}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,420] Trial 76 finished with value: 0.4747572360399296 and parameters: {'w1': 0.49382132217169633}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,426] Trial 77 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5488071192168911}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,434] Trial 78 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5853232163499137}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,441] Trial 79 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8105752777377577}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,449] Trial 80 finished with value: 0.4747572360399296 and parameters: {'w1': 0.65900449768352}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,457] Trial 81 finished with value: 0.4747572360399296 and parameters: {'w1': 0.41622204037331684}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,464] Trial 82 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5136495500621558}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,472] Trial 83 finished with value: 0.4747572360399296 and parameters: {'w1': 0.38884444378277183}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,479] Trial 84 finished with value: 0.4747572360399296 and parameters: {'w1': 0.44942280681783564}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,486] Trial 85 finished with value: 0.4747572360399296 and parameters: {'w1': 0.475838235326943}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,494] Trial 86 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5262524931196525}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,501] Trial 87 finished with value: 0.4747572360399296 and parameters: {'w1': 0.43315338292472433}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,509] Trial 88 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7114329715513262}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,515] Trial 89 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5440902782312205}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,523] Trial 90 finished with value: 0.4747572360399296 and parameters: {'w1': 0.39817427621687623}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,530] Trial 91 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8745630712456977}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,537] Trial 92 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3502014923812452}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,545] Trial 93 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7626539020149061}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,552] Trial 94 finished with value: 0.4747572360399296 and parameters: {'w1': 0.920644573416975}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,559] Trial 95 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7426576391314059}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,566] Trial 96 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6207634294929306}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:50,574] Trial 97 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8249335643597075}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,581] Trial 98 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8590573242979047}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,588] Trial 99 finished with value: 0.4747572360399296 and parameters: {'w1': 0.47778863321425813}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,595] Trial 100 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7857910336393209}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,602] Trial 101 finished with value: 0.4747572360399296 and parameters: {'w1': 0.05868647136850763}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,610] Trial 102 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5010954813499466}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,617] Trial 103 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5777602996543129}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,625] Trial 104 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6726538943561178}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,632] Trial 105 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6127102809315539}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,639] Trial 106 finished with value: 0.4747572360399296 and parameters: {'w1': 0.42228946845062626}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,646] Trial 107 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6014880631990537}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,654] Trial 108 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6927131394902493}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,662] Trial 109 finished with value: 0.4747572360399296 and parameters: {'w1': 0.36825596414464273}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,670] Trial 110 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3233224370197425}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,677] Trial 111 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9473610371587835}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,685] Trial 112 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7261026779025987}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,692] Trial 113 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8258741920615753}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,699] Trial 114 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4630300802134865}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,707] Trial 115 finished with value: 0.4747572360399296 and parameters: {'w1': 0.44475719112573503}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,715] Trial 116 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6496560760331577}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,723] Trial 117 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5124869687260238}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,731] Trial 118 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5649710702766233}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,738] Trial 119 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3974952651665409}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,745] Trial 120 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8073980196274064}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,753] Trial 121 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8942571424621493}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,760] Trial 122 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9626498709517778}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,768] Trial 123 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9757237105077985}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,776] Trial 124 finished with value: 0.4747572360399296 and parameters: {'w1': 0.918032743780072}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,783] Trial 125 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9311297230617164}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,791] Trial 126 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8855192467109276}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,798] Trial 127 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8623104878498901}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,806] Trial 128 finished with value: 0.4747572360399296 and parameters: {'w1': 0.999484706571037}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,813] Trial 129 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8972467472640596}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,820] Trial 130 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7158861589270629}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,827] Trial 131 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5321803926134623}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,834] Trial 132 finished with value: 0.4747572360399296 and parameters: {'w1': 0.48739156550425644}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,841] Trial 133 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5566609178901035}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,849] Trial 134 finished with value: 0.4747572360399296 and parameters: {'w1': 0.636003477976475}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,855] Trial 135 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6784002057635332}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,863] Trial 136 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5865024871365924}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,871] Trial 137 finished with value: 0.4747572360399296 and parameters: {'w1': 0.772205667610687}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,879] Trial 138 finished with value: 0.4747572360399296 and parameters: {'w1': 0.43804217162645437}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,886] Trial 139 finished with value: 0.4747572360399296 and parameters: {'w1': 0.46596183931113055}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,894] Trial 140 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7463624558989257}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,902] Trial 141 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8474936553798438}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,910] Trial 142 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6668534497280116}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,916] Trial 143 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9442449665987303}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,924] Trial 144 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9026343982632385}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,932] Trial 145 finished with value: 0.4747572360399296 and parameters: {'w1': 0.37727034253288183}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:50,940] Trial 146 finished with value: 0.4747572360399296 and parameters: {'w1': 0.872831958276028}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,948] Trial 147 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6953044076438357}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,955] Trial 148 finished with value: 0.4747572360399296 and parameters: {'w1': 0.636830680662495}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,962] Trial 149 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4204300866603982}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,969] Trial 150 finished with value: 0.4747572360399296 and parameters: {'w1': 0.295923092449259}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,977] Trial 151 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8112601433779112}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,985] Trial 152 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7943711169262083}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:50,993] Trial 153 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8455324878627112}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,000] Trial 154 finished with value: 0.4747572360399296 and parameters: {'w1': 0.768726476574102}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,008] Trial 155 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7335723546203471}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,016] Trial 156 finished with value: 0.4747572360399296 and parameters: {'w1': 0.15952059294348947}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,023] Trial 157 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5055289302703452}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,030] Trial 158 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5392455490660317}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,038] Trial 159 finished with value: 0.4747572360399296 and parameters: {'w1': 0.606129236867924}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,046] Trial 160 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4113327330526255}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,053] Trial 161 finished with value: 0.4747572360399296 and parameters: {'w1': 0.48926419838180496}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,060] Trial 162 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5760673672686178}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,068] Trial 163 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7163859802581589}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,076] Trial 164 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4672127024153767}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,084] Trial 165 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5544871044726111}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,091] Trial 166 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8262402715061837}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,100] Trial 167 finished with value: 0.4747572360399296 and parameters: {'w1': 0.43308558693272065}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,108] Trial 168 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5178265298876022}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,116] Trial 169 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7575613174377305}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,126] Trial 170 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6648565802238846}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,137] Trial 171 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9483335934237411}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,146] Trial 172 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9107525183949916}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,154] Trial 173 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8715461405011102}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,162] Trial 174 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5916829105314906}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,169] Trial 175 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6973823409061648}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,177] Trial 176 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9279384206839107}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,185] Trial 177 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8841192832355224}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,193] Trial 178 finished with value: 0.4747572360399296 and parameters: {'w1': 0.447828912082129}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,201] Trial 179 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6201903939048496}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,208] Trial 180 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7877469883507516}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,216] Trial 181 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3897768607516635}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,224] Trial 182 finished with value: 0.4747572360399296 and parameters: {'w1': 0.35374549256424576}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,232] Trial 183 finished with value: 0.4747572360399296 and parameters: {'w1': 0.011380705127295498}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,240] Trial 184 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4001298877649109}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,246] Trial 185 finished with value: 0.4747572360399296 and parameters: {'w1': 0.30516711647161093}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,253] Trial 186 finished with value: 0.4747572360399296 and parameters: {'w1': 0.958037369344822}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,260] Trial 187 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3356248401751891}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,267] Trial 188 finished with value: 0.4747572360399296 and parameters: {'w1': 0.48331553901117386}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,274] Trial 189 finished with value: 0.4747572360399296 and parameters: {'w1': 0.24824571367022566}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,281] Trial 190 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9369732998177308}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,289] Trial 191 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8588791401376185}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,296] Trial 192 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9142621529954794}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,303] Trial 193 finished with value: 0.4747572360399296 and parameters: {'w1': 0.825959957367492}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,310] Trial 194 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4209227802165119}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:51,317] Trial 195 finished with value: 0.4747572360399296 and parameters: {'w1': 0.379389684870846}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,325] Trial 196 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5287008165137119}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,332] Trial 197 finished with value: 0.4747572360399296 and parameters: {'w1': 0.1876107903876132}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,340] Trial 198 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9679296625121736}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,347] Trial 199 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7531947060305119}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,355] Trial 200 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9826725080891124}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,363] Trial 201 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9741442443513331}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,371] Trial 202 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9353590954982594}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,379] Trial 203 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4493100052344278}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,386] Trial 204 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8895833010411561}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,394] Trial 205 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7791025975844726}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,402] Trial 206 finished with value: 0.4747572360399296 and parameters: {'w1': 0.989771340605766}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,410] Trial 207 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9545377923431695}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,419] Trial 208 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9953975120499197}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,427] Trial 209 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8036519694141824}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,434] Trial 210 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2766677725939533}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,441] Trial 211 finished with value: 0.4747572360399296 and parameters: {'w1': 0.33885328917629104}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,449] Trial 212 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7352660058019034}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,456] Trial 213 finished with value: 0.4747572360399296 and parameters: {'w1': 0.37219276055690875}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,464] Trial 214 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6501966198734221}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,471] Trial 215 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5055059224995296}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,479] Trial 216 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8453476891348146}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,486] Trial 217 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6808175806328176}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,493] Trial 218 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4674475688938402}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,501] Trial 219 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9007742043857235}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,509] Trial 220 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5526910430049435}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,516] Trial 221 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5980355295138027}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,523] Trial 222 finished with value: 0.4747572360399296 and parameters: {'w1': 0.57486248335886}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,531] Trial 223 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5379865788892212}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,538] Trial 224 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4127738236880176}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,546] Trial 225 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7089047908173659}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,553] Trial 226 finished with value: 0.4747572360399296 and parameters: {'w1': 0.92085253621665}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,561] Trial 227 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2171471094936933}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,568] Trial 228 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3597032199424477}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,576] Trial 229 finished with value: 0.4747572360399296 and parameters: {'w1': 0.563913629814928}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,583] Trial 230 finished with value: 0.4747572360399296 and parameters: {'w1': 0.11279163820570326}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,591] Trial 231 finished with value: 0.4747572360399296 and parameters: {'w1': 0.525204133879866}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,599] Trial 232 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2554215781991127}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,606] Trial 233 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4904417893205662}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,613] Trial 234 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4383609288951129}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,620] Trial 235 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3954706694839531}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,628] Trial 236 finished with value: 0.4747572360399296 and parameters: {'w1': 0.28076262073524605}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,636] Trial 237 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6251219612033331}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,644] Trial 238 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9609716631606079}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,652] Trial 239 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8144613889512017}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,659] Trial 240 finished with value: 0.4747572360399296 and parameters: {'w1': 0.33527771914458887}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,667] Trial 241 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8606189076988637}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,675] Trial 242 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6474166279040099}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,682] Trial 243 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9428915291329467}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:51,690] Trial 244 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8368715239653226}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,697] Trial 245 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6733626792198794}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,705] Trial 246 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6064776641782155}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,713] Trial 247 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5766089151207593}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,720] Trial 248 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6906522067633603}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,728] Trial 249 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5466023997689377}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,736] Trial 250 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8735563754872727}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,743] Trial 251 finished with value: 0.4747572360399296 and parameters: {'w1': 0.787320029511481}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,751] Trial 252 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5133046818587091}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,758] Trial 253 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3207889306094502}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,766] Trial 254 finished with value: 0.4747572360399296 and parameters: {'w1': 0.21415427884046423}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,773] Trial 255 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9761335468789245}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,781] Trial 256 finished with value: 0.4747572360399296 and parameters: {'w1': 0.11049312772758557}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,788] Trial 257 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3053819384914488}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,796] Trial 258 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9098321284738426}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,805] Trial 259 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6557213208829744}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,813] Trial 260 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4587756596413297}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,820] Trial 261 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4242749039759037}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,828] Trial 262 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7642424877706546}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,835] Trial 263 finished with value: 0.4747572360399296 and parameters: {'w1': 0.35320914818633403}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,843] Trial 264 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7194384444498211}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,850] Trial 265 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6261403191974165}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,858] Trial 266 finished with value: 0.4747572360399296 and parameters: {'w1': 0.47717233306710294}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,865] Trial 267 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9995073361051068}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,873] Trial 268 finished with value: 0.4747572360399296 and parameters: {'w1': 0.37772232439456355}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,880] Trial 269 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5601138140978863}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,888] Trial 270 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5867049300163154}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,895] Trial 271 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8043972113957394}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,903] Trial 272 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9319344808409742}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,911] Trial 273 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5293151210274667}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,918] Trial 274 finished with value: 0.4747572360399296 and parameters: {'w1': 0.844125657742699}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,926] Trial 275 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8886715345344552}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,934] Trial 276 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2710331905456162}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,941] Trial 277 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4030623642143132}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,949] Trial 278 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7447167387379734}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,956] Trial 279 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6940228435414999}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,964] Trial 280 finished with value: 0.4747572360399296 and parameters: {'w1': 0.440265672059755}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,971] Trial 281 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5037118680738304}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,979] Trial 282 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3203702839631776}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,986] Trial 283 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9629971477409287}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:51,994] Trial 284 finished with value: 0.4747572360399296 and parameters: {'w1': 0.039090969983262655}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,001] Trial 285 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6054738754864024}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,009] Trial 286 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8308252348639691}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,017] Trial 287 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2983243563447448}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,024] Trial 288 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9190390282446138}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,032] Trial 289 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6692474497732116}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,040] Trial 290 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2337490350818315}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,048] Trial 291 finished with value: 0.4747572360399296 and parameters: {'w1': 0.17632181040953301}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,056] Trial 292 finished with value: 0.4747572360399296 and parameters: {'w1': 0.948385356525501}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:52,064] Trial 293 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5444805265005602}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,072] Trial 294 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6326000336886708}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,080] Trial 295 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7839712208602304}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,087] Trial 296 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8720866456820826}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,095] Trial 297 finished with value: 0.4747572360399296 and parameters: {'w1': 0.36103104405127184}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,102] Trial 298 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7262547131932285}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,110] Trial 299 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5847810555700896}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,118] Trial 300 finished with value: 0.4747572360399296 and parameters: {'w1': 0.09115533376119533}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,125] Trial 301 finished with value: 0.4747572360399296 and parameters: {'w1': 0.980285680172742}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,133] Trial 302 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8180025503644097}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,141] Trial 303 finished with value: 0.4747572360399296 and parameters: {'w1': 0.02071421576012178}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,148] Trial 304 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4575976761053317}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,156] Trial 305 finished with value: 0.4747572360399296 and parameters: {'w1': 0.42509704502357915}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,164] Trial 306 finished with value: 0.4747572360399296 and parameters: {'w1': 0.14176063392772076}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,172] Trial 307 finished with value: 0.4747572360399296 and parameters: {'w1': 0.07677633416336505}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,179] Trial 308 finished with value: 0.4747572360399296 and parameters: {'w1': 0.904894556495484}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,187] Trial 309 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2012470682525471}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,195] Trial 310 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5009803148308509}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,203] Trial 311 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3964606687542329}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,211] Trial 312 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9344042659881932}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,219] Trial 313 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2510416366622813}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,227] Trial 314 finished with value: 0.4747572360399296 and parameters: {'w1': 0.480784903777386}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,235] Trial 315 finished with value: 0.4747572360399296 and parameters: {'w1': 0.16208914628490878}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,243] Trial 316 finished with value: 0.4747572360399296 and parameters: {'w1': 0.564377699024067}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,251] Trial 317 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8524307714336756}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,259] Trial 318 finished with value: 0.4747572360399296 and parameters: {'w1': 0.23039571362610095}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,267] Trial 319 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7017664372228037}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,274] Trial 320 finished with value: 0.4747572360399296 and parameters: {'w1': 0.33869714906261467}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,282] Trial 321 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7715642422236406}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,290] Trial 322 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6473714298403986}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,298] Trial 323 finished with value: 0.4747572360399296 and parameters: {'w1': 0.13900097065648997}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,306] Trial 324 finished with value: 0.4747572360399296 and parameters: {'w1': 0.04199010876051901}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,314] Trial 325 finished with value: 0.4747572360399296 and parameters: {'w1': 0.18707965121990391}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,322] Trial 326 finished with value: 0.4747572360399296 and parameters: {'w1': 0.26838011943688134}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,330] Trial 327 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5219115908348921}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,338] Trial 328 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8886755526239609}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,346] Trial 329 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2957241484563688}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,354] Trial 330 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9594180436285231}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,362] Trial 331 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5405340340634074}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,370] Trial 332 finished with value: 0.4747572360399296 and parameters: {'w1': 0.802826489924815}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,378] Trial 333 finished with value: 0.4747572360399296 and parameters: {'w1': 0.41140392527185715}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,386] Trial 334 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3762690012418517}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,394] Trial 335 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7566659099836331}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,402] Trial 336 finished with value: 0.4747572360399296 and parameters: {'w1': 0.45663474535425397}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,410] Trial 337 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6754088571615776}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,418] Trial 338 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6076090597546211}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,426] Trial 339 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9265032056469648}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,434] Trial 340 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4373299929022196}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,442] Trial 341 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9734169149394729}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:52,451] Trial 342 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8585692046939477}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,459] Trial 343 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6558201161147172}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,467] Trial 344 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7147880145817713}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,475] Trial 345 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2190369574931248}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,483] Trial 346 finished with value: 0.4747572360399296 and parameters: {'w1': 0.062316875471861426}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,492] Trial 347 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5564678191147084}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,500] Trial 348 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5804466170008471}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,508] Trial 349 finished with value: 0.4747572360399296 and parameters: {'w1': 0.0038827941613664985}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,516] Trial 350 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9016501767427242}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,524] Trial 351 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7376405174349194}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,532] Trial 352 finished with value: 0.4747572360399296 and parameters: {'w1': 0.819767228869512}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,540] Trial 353 finished with value: 0.4747572360399296 and parameters: {'w1': 0.24166214604794525}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,549] Trial 354 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6280061517555425}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,557] Trial 355 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4973546352175014}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,566] Trial 356 finished with value: 0.4747572360399296 and parameters: {'w1': 0.20269632316354036}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,574] Trial 357 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9949168578971986}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,582] Trial 358 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9463272497642052}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,590] Trial 359 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6886453131020958}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,598] Trial 360 finished with value: 0.4747572360399296 and parameters: {'w1': 0.25998965729742984}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,607] Trial 361 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4766161040911839}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,615] Trial 362 finished with value: 0.4747572360399296 and parameters: {'w1': 0.36213411827322023}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,623] Trial 363 finished with value: 0.4747572360399296 and parameters: {'w1': 0.39250959001400076}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,631] Trial 364 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2843333094531497}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,639] Trial 365 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5191846487916798}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,647] Trial 366 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3244562875852921}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,655] Trial 367 finished with value: 0.4747572360399296 and parameters: {'w1': 0.87363738157965}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,664] Trial 368 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8376109678396996}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,672] Trial 369 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4212868648375044}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,680] Trial 370 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5700519123140306}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,688] Trial 371 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7797578871068445}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,697] Trial 372 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7976963451183056}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,705] Trial 373 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6113617375767432}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,713] Trial 374 finished with value: 0.4747572360399296 and parameters: {'w1': 0.13394765023941407}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,721] Trial 375 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9097368650960009}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,730] Trial 376 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5396333623942645}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,738] Trial 377 finished with value: 0.4747572360399296 and parameters: {'w1': 0.34758856341119704}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,746] Trial 378 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3003439912269867}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,754] Trial 379 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5944529638217558}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,763] Trial 380 finished with value: 0.4747572360399296 and parameters: {'w1': 0.16586543663150768}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,771] Trial 381 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4521242678360062}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,779] Trial 382 finished with value: 0.4747572360399296 and parameters: {'w1': 0.66088499906873}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,787] Trial 383 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7127227947028528}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,796] Trial 384 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3167021415723319}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,804] Trial 385 finished with value: 0.4747572360399296 and parameters: {'w1': 0.08287680916799048}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,813] Trial 386 finished with value: 0.4747572360399296 and parameters: {'w1': 0.03206956647002468}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,822] Trial 387 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9457052196161241}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,830] Trial 388 finished with value: 0.4747572360399296 and parameters: {'w1': 0.978483783799221}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,838] Trial 389 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8835859379341459}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,847] Trial 390 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6819275137217186}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:52,855] Trial 391 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3850473874267253}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,863] Trial 392 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6413499083114732}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,872] Trial 393 finished with value: 0.4747572360399296 and parameters: {'w1': 0.04795607663202778}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,881] Trial 394 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9267678490524579}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,889] Trial 395 finished with value: 0.4747572360399296 and parameters: {'w1': 0.48936819572984314}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,897] Trial 396 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7516123277871962}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,905] Trial 397 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4127858210832778}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,914] Trial 398 finished with value: 0.4747572360399296 and parameters: {'w1': 0.015935959350092725}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,922] Trial 399 finished with value: 0.4747572360399296 and parameters: {'w1': 0.19497538730136987}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,930] Trial 400 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8311672810832211}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,939] Trial 401 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8553553030973386}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,947] Trial 402 finished with value: 0.4747572360399296 and parameters: {'w1': 0.26487419577750065}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,955] Trial 403 finished with value: 0.4747572360399296 and parameters: {'w1': 0.07146488950034002}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,964] Trial 404 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5283889360326643}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,972] Trial 405 finished with value: 0.4747572360399296 and parameters: {'w1': 0.17482880422807268}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,980] Trial 406 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4388277634383038}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,989] Trial 407 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9610097243059665}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:52,997] Trial 408 finished with value: 0.4747572360399296 and parameters: {'w1': 0.735095824203592}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,006] Trial 409 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7969760425554206}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,014] Trial 410 finished with value: 0.4747572360399296 and parameters: {'w1': 0.09021924927770278}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,023] Trial 411 finished with value: 0.4747572360399296 and parameters: {'w1': 0.28574322692053317}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,031] Trial 412 finished with value: 0.4747572360399296 and parameters: {'w1': 0.23969905012633874}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,040] Trial 413 finished with value: 0.4747572360399296 and parameters: {'w1': 0.46584898800792446}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,049] Trial 414 finished with value: 0.4747572360399296 and parameters: {'w1': 0.10479714910561792}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,057] Trial 415 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5080968606826056}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,066] Trial 416 finished with value: 0.4747572360399296 and parameters: {'w1': 0.06191460381936875}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,074] Trial 417 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5674697210791932}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,083] Trial 418 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7017734341259515}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,093] Trial 419 finished with value: 0.4747572360399296 and parameters: {'w1': 0.1488110367177972}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,101] Trial 420 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3642488174194341}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,111] Trial 421 finished with value: 0.4747572360399296 and parameters: {'w1': 0.10827248423171107}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,119] Trial 422 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5489692726069186}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,128] Trial 423 finished with value: 0.4747572360399296 and parameters: {'w1': 0.21839734054263804}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,137] Trial 424 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5936507036822025}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,146] Trial 425 finished with value: 0.4747572360399296 and parameters: {'w1': 0.896021927062599}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,155] Trial 426 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3387930941583972}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,164] Trial 427 finished with value: 0.4747572360399296 and parameters: {'w1': 0.12363076863354305}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,172] Trial 428 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6168504433582814}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,181] Trial 429 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9987643504688939}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,190] Trial 430 finished with value: 0.4747572360399296 and parameters: {'w1': 0.764936259582338}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,199] Trial 431 finished with value: 0.4747572360399296 and parameters: {'w1': 0.15803632993122121}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,207] Trial 432 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8131209728103743}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,216] Trial 433 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9171007852239109}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,225] Trial 434 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9369310574989895}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,234] Trial 435 finished with value: 0.4747572360399296 and parameters: {'w1': 0.42401599631169273}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,244] Trial 436 finished with value: 0.4747572360399296 and parameters: {'w1': 0.007237707410339467}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,254] Trial 437 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8706499749476984}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,264] Trial 438 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6725199497474916}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,275] Trial 439 finished with value: 0.4747572360399296 and parameters: {'w1': 0.38979063705142214}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:53,288] Trial 440 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6445647494152726}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,301] Trial 441 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9563813257354888}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,310] Trial 442 finished with value: 0.4747572360399296 and parameters: {'w1': 0.30694449613500985}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,321] Trial 443 finished with value: 0.4747572360399296 and parameters: {'w1': 0.48870473544089804}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,329] Trial 444 finished with value: 0.4747572360399296 and parameters: {'w1': 0.11985176680263104}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,338] Trial 445 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8425495376299087}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,347] Trial 446 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9772651939929955}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,358] Trial 447 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4706954364515482}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,367] Trial 448 finished with value: 0.4747572360399296 and parameters: {'w1': 0.03099748376259198}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,377] Trial 449 finished with value: 0.4747572360399296 and parameters: {'w1': 0.324859529494582}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,386] Trial 450 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7247015095450746}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,396] Trial 451 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7892020205342056}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,405] Trial 452 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5142324202532904}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,413] Trial 453 finished with value: 0.4747572360399296 and parameters: {'w1': 0.44547455930840735}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,422] Trial 454 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5745655267404535}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,431] Trial 455 finished with value: 0.4747572360399296 and parameters: {'w1': 0.054575623370745764}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,440] Trial 456 finished with value: 0.4747572360399296 and parameters: {'w1': 0.24349804605138892}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,449] Trial 457 finished with value: 0.4747572360399296 and parameters: {'w1': 0.20362107709118843}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,458] Trial 458 finished with value: 0.4747572360399296 and parameters: {'w1': 0.2655274267050648}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,466] Trial 459 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5448153139504178}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,475] Trial 460 finished with value: 0.4747572360399296 and parameters: {'w1': 0.35054570400516805}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,484] Trial 461 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6872939188739303}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,493] Trial 462 finished with value: 0.4747572360399296 and parameters: {'w1': 0.41226116582511574}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,502] Trial 463 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6261578165979248}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,510] Trial 464 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9034271676621458}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,519] Trial 465 finished with value: 0.4747572360399296 and parameters: {'w1': 0.28709128227280656}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,528] Trial 466 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8251673933552747}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,537] Trial 467 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8845499924900301}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,546] Trial 468 finished with value: 0.4747572360399296 and parameters: {'w1': 0.13402934849992587}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,555] Trial 469 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7724910945025637}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,564] Trial 470 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6607089299899542}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,572] Trial 471 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9324016992602155}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,581] Trial 472 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8568694588885003}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,590] Trial 473 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5975005994922363}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,599] Trial 474 finished with value: 0.4747572360399296 and parameters: {'w1': 0.39772991509141103}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,608] Trial 475 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5283850076768466}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,617] Trial 476 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7468522766347955}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,626] Trial 477 finished with value: 0.4747572360399296 and parameters: {'w1': 0.18349012488626337}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,635] Trial 478 finished with value: 0.4747572360399296 and parameters: {'w1': 0.702059753401094}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,644] Trial 479 finished with value: 0.4747572360399296 and parameters: {'w1': 0.37961643607010925}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,653] Trial 480 finished with value: 0.4747572360399296 and parameters: {'w1': 0.554666977498883}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,662] Trial 481 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9632931436535211}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,671] Trial 482 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4365604980482008}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,681] Trial 483 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5000142331202416}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,690] Trial 484 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9991898652741675}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,699] Trial 485 finished with value: 0.4747572360399296 and parameters: {'w1': 0.10061970230799161}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,708] Trial 486 finished with value: 0.4747572360399296 and parameters: {'w1': 0.15818183165675423}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,717] Trial 487 finished with value: 0.4747572360399296 and parameters: {'w1': 0.07816461354027339}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,726] Trial 488 finished with value: 0.4747572360399296 and parameters: {'w1': 9.361030101760759e-05}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 12:01:53,735] Trial 489 finished with value: 0.4747572360399296 and parameters: {'w1': 0.4611075261852314}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,744] Trial 490 finished with value: 0.4747572360399296 and parameters: {'w1': 0.5834698059577061}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,753] Trial 491 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3661465327272001}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,762] Trial 492 finished with value: 0.4747572360399296 and parameters: {'w1': 0.8136001940002842}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,771] Trial 493 finished with value: 0.4747572360399296 and parameters: {'w1': 0.3349196005519432}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,780] Trial 494 finished with value: 0.4747572360399296 and parameters: {'w1': 0.221985672503286}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,789] Trial 495 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9124721040804746}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,798] Trial 496 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7217965446468575}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,807] Trial 497 finished with value: 0.4747572360399296 and parameters: {'w1': 0.6432929626213457}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,815] Trial 498 finished with value: 0.4747572360399296 and parameters: {'w1': 0.9469204974873822}. Best is trial 0 with value: 0.4747572360399296.\n",
      "[I 2023-10-12 12:01:53,825] Trial 499 finished with value: 0.4747572360399296 and parameters: {'w1': 0.7908244449008619}. Best is trial 0 with value: 0.4747572360399296.\n"
     ]
    }
   ],
   "source": [
    "def reduce_rmse(params):    \n",
    "    for index, val  in enumerate(params):\n",
    "        if index == 0:            \n",
    "            preds = params[val]*oofs[0][['content_pred', 'wording_pred']].values\n",
    "        else:\n",
    "            preds += params[val]*oofs[index][['content_pred', 'wording_pred']].values\n",
    "    \n",
    "    param_sum = 0\n",
    "    for key, val in params.items():\n",
    "        param_sum += val\n",
    "\n",
    "    preds = preds/param_sum\n",
    "    \n",
    "    score, _ = get_score(true_labels_oof, preds, single=True)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    params = {}    \n",
    "    for i in range(len(oofs)):\n",
    "        params[f\"w{i+1}\"] = trial.suggest_float(f'w{i+1}', 0, 1) \n",
    "        \n",
    "    score = reduce_rmse(params)\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a2a9d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': 0.8846156258427612}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7e7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb9aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a7f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7331511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params # 0.5210540444629375 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "58ae069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 0.7039470880705468\n",
      "0.7039470880705468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4826655974659348, [0.4183766427459229, 0.5469545521859467])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = best_params\n",
    "\n",
    "preds_final = None\n",
    "\n",
    "\n",
    "for idx, (model_key, model_wt) in enumerate(weights.items()):\n",
    "    print(model_key, model_wt)\n",
    "    if idx == 0:\n",
    "        preds_final = oofs[idx][['content_pred', 'wording_pred']].values * model_wt\n",
    "    else:\n",
    "        preds_final += oofs[idx][['content_pred', 'wording_pred']].values * model_wt\n",
    "preds_final = preds_final/np.sum(list(weights.values()))\n",
    "print(np.sum(list(weights.values())))\n",
    "\n",
    "model_ensemble = oofs[0].copy()\n",
    "model_ensemble[['content_pred', 'wording_pred']] = preds_final\n",
    "\n",
    "\n",
    "score, scores = get_score(true_labels_oof, preds_final)\n",
    "score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc0bb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble = model_ensemble.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f7962e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenize_length</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.282615</td>\n",
       "      <td>-1.338554</td>\n",
       "      <td>ad7245db300c</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[SUMMARY_START]The main person is a likable pe...</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.338856</td>\n",
       "      <td>-1.126083</td>\n",
       "      <td>c4433d2e4905</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[SUMMARY_START]An ideal tragedy as described b...</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.424251</td>\n",
       "      <td>-1.332204</td>\n",
       "      <td>ac8891e90289</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[SUMMARY_START]a complex twisting plot that ma...</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.290172</td>\n",
       "      <td>-1.414644</td>\n",
       "      <td>e16cafc1509a</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[SUMMARY_START]At least 3 elements of an ideal...</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.277248</td>\n",
       "      <td>-1.151478</td>\n",
       "      <td>551c0f2ac3de</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[SUMMARY_START]An ideal tragedy must have a  c...</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>2.488900</td>\n",
       "      <td>2.252955</td>\n",
       "      <td>a04bba18f7d2</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[SUMMARY_START]The way that the Third Wave exp...</td>\n",
       "      <td>1030</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>2.084769</td>\n",
       "      <td>2.026452</td>\n",
       "      <td>11c3509b7b43</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[SUMMARY_START]The Third Wave developed over s...</td>\n",
       "      <td>1063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>2.816301</td>\n",
       "      <td>2.524373</td>\n",
       "      <td>9ecc3600af3f</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[SUMMARY_START]The Third Wave started as a exp...</td>\n",
       "      <td>1078</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>2.845079</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>e12feeaa31c0</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[SUMMARY_START]The Third Wave developed in suc...</td>\n",
       "      <td>1102</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>2.724438</td>\n",
       "      <td>2.048518</td>\n",
       "      <td>74545d29969c</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[SUMMARY_START]The Third Wave, a five-day expe...</td>\n",
       "      <td>1166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       content   wording    student_id prompt_id  \\\n",
       "0    -1.282615 -1.338554  ad7245db300c    39c16e   \n",
       "1    -1.338856 -1.126083  c4433d2e4905    39c16e   \n",
       "2    -1.424251 -1.332204  ac8891e90289    39c16e   \n",
       "3    -1.290172 -1.414644  e16cafc1509a    39c16e   \n",
       "4    -1.277248 -1.151478  551c0f2ac3de    39c16e   \n",
       "...        ...       ...           ...       ...   \n",
       "7160  2.488900  2.252955  a04bba18f7d2    814d6b   \n",
       "7161  2.084769  2.026452  11c3509b7b43    814d6b   \n",
       "7162  2.816301  2.524373  9ecc3600af3f    814d6b   \n",
       "7163  2.845079  2.200934  e12feeaa31c0    814d6b   \n",
       "7164  2.724438  2.048518  74545d29969c    814d6b   \n",
       "\n",
       "                                                   text  tokenize_length  fold  \n",
       "0     [SUMMARY_START]The main person is a likable pe...              769     0  \n",
       "1     [SUMMARY_START]An ideal tragedy as described b...              770     0  \n",
       "2     [SUMMARY_START]a complex twisting plot that ma...              770     0  \n",
       "3     [SUMMARY_START]At least 3 elements of an ideal...              771     0  \n",
       "4     [SUMMARY_START]An ideal tragedy must have a  c...              771     0  \n",
       "...                                                 ...              ...   ...  \n",
       "7160  [SUMMARY_START]The way that the Third Wave exp...             1030     3  \n",
       "7161  [SUMMARY_START]The Third Wave developed over s...             1063     3  \n",
       "7162  [SUMMARY_START]The Third Wave started as a exp...             1078     3  \n",
       "7163  [SUMMARY_START]The Third Wave developed in suc...             1102     3  \n",
       "7164  [SUMMARY_START]The Third Wave, a five-day expe...             1166     3  \n",
       "\n",
       "[7165 rows x 7 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8185b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/rohits/pv1/commonlit/data/raw/train_folds_processed.csv\")\n",
    "train= train.loc[train.fold.isin([0,1,2,3])].sort_values('student_id').reset_index(drop=True)\n",
    "\n",
    "dfs = []\n",
    "for csv in csvs:\n",
    "    print\n",
    "    model_name = csv.split(\"/\")[-1].split(\".\")[0]\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.loc[df.fold.isin([0,1,2,3])]\n",
    "    df = df.loc[df.student_id.isin(train_df.student_id.values)].sort_values('student_id').reset_index(drop=True)\n",
    "    df = df[['student_id', 'content', 'wording']]\n",
    "    train[[f'content_{model_name}', f'wording_{model_name}']] = df[['content', 'wording']]\n",
    "    \n",
    "    \n",
    "# # # ## add weighted ensemble\n",
    "# model_ensemble = model_ensemble.loc[df.student_id.isin(train.student_id.values)].sort_values('student_id').reset_index(drop=True)\n",
    "# model_ensemble = model_ensemble[['student_id', 'content_pred', 'wording_pred']]\n",
    "# train[[f'content_ensemble', f'wording_ensemble']] = model_ensemble[['content_pred', 'wording_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc2285c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>fold</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>word_overlap_count</th>\n",
       "      <th>bigram_overlap_count</th>\n",
       "      <th>trigram_overlap_count</th>\n",
       "      <th>quotes_count</th>\n",
       "      <th>bart-large-cnn</th>\n",
       "      <th>content_model250_avg</th>\n",
       "      <th>wording_model250_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>671</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Third Wave experiment took place at Cubbe...</td>\n",
       "      <td>-0.043972</td>\n",
       "      <td>0.889765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>1137</td>\n",
       "      <td>0.049252</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>With one member trimming beef in a cannery, a...</td>\n",
       "      <td>-0.517902</td>\n",
       "      <td>-0.221838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "\n",
       "    content   wording  fold  summary_length  splling_err_num  \\\n",
       "0  0.205683  0.380538     3              69                5   \n",
       "1 -0.548304  0.506755     2              56                2   \n",
       "\n",
       "                                     prompt_question             prompt_title  \\\n",
       "0  Summarize how the Third Wave developed over su...           The Third Wave   \n",
       "1  Summarize the various ways the factory would u...  Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  prompt_length  \\\n",
       "0  Background \\r\\nThe Third Wave experiment took ...            671   \n",
       "1  With one member trimming beef in a cannery, an...           1137   \n",
       "\n",
       "   length_ratio  word_overlap_count  bigram_overlap_count  \\\n",
       "0      0.102832                   0                     5   \n",
       "1      0.049252                   0                    22   \n",
       "\n",
       "   trigram_overlap_count  quotes_count  \\\n",
       "0                      0             0   \n",
       "1                     10             0   \n",
       "\n",
       "                                      bart-large-cnn  content_model250_avg  \\\n",
       "0   The Third Wave experiment took place at Cubbe...             -0.043972   \n",
       "1   With one member trimming beef in a cannery, a...             -0.517902   \n",
       "\n",
       "   wording_model250_avg  \n",
       "0              0.889765  \n",
       "1             -0.221838  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9400a5c",
   "metadata": {},
   "source": [
    "## LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5fa3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "targets = [\"content\", \"wording\"]\n",
    "\n",
    "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\", \"bart-large-cnn\", # \"quotes_count\", \"trigram_overlap_count\", \"bigram_overlap_count\", \"word_overlap_count\"\n",
    "               ] + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36e9248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'summary_length', 'splling_err_num', 'prompt_length', 'length_ratio',\n",
    "#        'word_overlap_count', 'bigram_overlap_count', 'trigram_overlap_count',\n",
    "#        'quotes_count', 'content_model2', 'wording_model2', 'content_model201',\n",
    "#        'wording_model201', 'content_ensemble', 'wording_ensemble'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74d64f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_length, splling_err_num, prompt_length, length_ratio, word_overlap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b67c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cd88e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5108 entries, 0 to 7164\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         5108 non-null   int64  \n",
      " 1   splling_err_num        5108 non-null   int64  \n",
      " 2   prompt_length          5108 non-null   int64  \n",
      " 3   length_ratio           5108 non-null   float64\n",
      " 4   word_overlap_count     5108 non-null   int64  \n",
      " 5   bigram_overlap_count   5108 non-null   int64  \n",
      " 6   trigram_overlap_count  5108 non-null   int64  \n",
      " 7   quotes_count           5108 non-null   int64  \n",
      " 8   content_model250_avg   5108 non-null   float64\n",
      " 9   wording_model250_avg   5108 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 439.0 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.017606\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.688123\n",
      "[20]\ttrain's rmse: 0.530985\n",
      "[30]\ttrain's rmse: 0.452514\n",
      "[40]\ttrain's rmse: 0.415176\n",
      "[50]\ttrain's rmse: 0.396402\n",
      "[60]\ttrain's rmse: 0.385771\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's rmse: 0.381038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's rmse: 0.379527\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttrain's rmse: 0.378167\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttrain's rmse: 0.377004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[110]\ttrain's rmse: 0.376132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's rmse: 0.375986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttrain's rmse: 0.376042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's rmse: 0.376149\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttrain's rmse: 0.376451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttrain's rmse: 0.375919\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5156 entries, 0 to 7164\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         5156 non-null   int64  \n",
      " 1   splling_err_num        5156 non-null   int64  \n",
      " 2   prompt_length          5156 non-null   int64  \n",
      " 3   length_ratio           5156 non-null   float64\n",
      " 4   word_overlap_count     5156 non-null   int64  \n",
      " 5   bigram_overlap_count   5156 non-null   int64  \n",
      " 6   trigram_overlap_count  5156 non-null   int64  \n",
      " 7   quotes_count           5156 non-null   int64  \n",
      " 8   content_model250_avg   5156 non-null   float64\n",
      " 9   wording_model250_avg   5156 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 443.1 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1368\n",
      "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.039959\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.769492\n",
      "[20]\ttrain's rmse: 0.578706\n",
      "[30]\ttrain's rmse: 0.499179\n",
      "[40]\ttrain's rmse: 0.476348\n",
      "[50]\ttrain's rmse: 0.472246\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttrain's rmse: 0.476796\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's rmse: 0.483696\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttrain's rmse: 0.472016\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5169 entries, 0 to 7163\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         5169 non-null   int64  \n",
      " 1   splling_err_num        5169 non-null   int64  \n",
      " 2   prompt_length          5169 non-null   int64  \n",
      " 3   length_ratio           5169 non-null   float64\n",
      " 4   word_overlap_count     5169 non-null   int64  \n",
      " 5   bigram_overlap_count   5169 non-null   int64  \n",
      " 6   trigram_overlap_count  5169 non-null   int64  \n",
      " 7   quotes_count           5169 non-null   int64  \n",
      " 8   content_model250_avg   5169 non-null   float64\n",
      " 9   wording_model250_avg   5169 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 444.2 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1347\n",
      "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.013356\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.688367\n",
      "[20]\ttrain's rmse: 0.522681\n",
      "[30]\ttrain's rmse: 0.44739\n",
      "[40]\ttrain's rmse: 0.424865\n",
      "[50]\ttrain's rmse: 0.420421\n",
      "[60]\ttrain's rmse: 0.423165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's rmse: 0.426899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's rmse: 0.429003\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttrain's rmse: 0.42032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6062 entries, 1 to 7164\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         6062 non-null   int64  \n",
      " 1   splling_err_num        6062 non-null   int64  \n",
      " 2   prompt_length          6062 non-null   int64  \n",
      " 3   length_ratio           6062 non-null   float64\n",
      " 4   word_overlap_count     6062 non-null   int64  \n",
      " 5   bigram_overlap_count   6062 non-null   int64  \n",
      " 6   trigram_overlap_count  6062 non-null   int64  \n",
      " 7   quotes_count           6062 non-null   int64  \n",
      " 8   content_model250_avg   6062 non-null   float64\n",
      " 9   wording_model250_avg   6062 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 521.0 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1401\n",
      "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.044904\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.846261\n",
      "[20]\ttrain's rmse: 0.67857\n",
      "[30]\ttrain's rmse: 0.588183\n",
      "[40]\ttrain's rmse: 0.542367\n",
      "[50]\ttrain's rmse: 0.518968\n",
      "[60]\ttrain's rmse: 0.506729\n",
      "[70]\ttrain's rmse: 0.503211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's rmse: 0.505872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttrain's rmse: 0.506923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttrain's rmse: 0.509035\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttrain's rmse: 0.503113\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5108 entries, 0 to 7164\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         5108 non-null   int64  \n",
      " 1   splling_err_num        5108 non-null   int64  \n",
      " 2   prompt_length          5108 non-null   int64  \n",
      " 3   length_ratio           5108 non-null   float64\n",
      " 4   word_overlap_count     5108 non-null   int64  \n",
      " 5   bigram_overlap_count   5108 non-null   int64  \n",
      " 6   trigram_overlap_count  5108 non-null   int64  \n",
      " 7   quotes_count           5108 non-null   int64  \n",
      " 8   content_model250_avg   5108 non-null   float64\n",
      " 9   wording_model250_avg   5108 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 439.0 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1394\n",
      "[LightGBM] [Info] Number of data points in the train set: 5108, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.031791\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.791124\n",
      "[20]\ttrain's rmse: 0.643569\n",
      "[30]\ttrain's rmse: 0.572195\n",
      "[40]\ttrain's rmse: 0.542081\n",
      "[50]\ttrain's rmse: 0.531907\n",
      "[60]\ttrain's rmse: 0.533541\n",
      "[70]\ttrain's rmse: 0.540528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's rmse: 0.550397\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttrain's rmse: 0.531214\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5156 entries, 0 to 7164\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         5156 non-null   int64  \n",
      " 1   splling_err_num        5156 non-null   int64  \n",
      " 2   prompt_length          5156 non-null   int64  \n",
      " 3   length_ratio           5156 non-null   float64\n",
      " 4   word_overlap_count     5156 non-null   int64  \n",
      " 5   bigram_overlap_count   5156 non-null   int64  \n",
      " 6   trigram_overlap_count  5156 non-null   int64  \n",
      " 7   quotes_count           5156 non-null   int64  \n",
      " 8   content_model250_avg   5156 non-null   float64\n",
      " 9   wording_model250_avg   5156 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 443.1 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1368\n",
      "[LightGBM] [Info] Number of data points in the train set: 5156, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.060941\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.728584\n",
      "[20]\ttrain's rmse: 0.628348\n",
      "[30]\ttrain's rmse: 0.59643\n",
      "[40]\ttrain's rmse: 0.600297\n",
      "[50]\ttrain's rmse: 0.618302\n",
      "[60]\ttrain's rmse: 0.633228\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttrain's rmse: 0.594418\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5169 entries, 0 to 7163\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         5169 non-null   int64  \n",
      " 1   splling_err_num        5169 non-null   int64  \n",
      " 2   prompt_length          5169 non-null   int64  \n",
      " 3   length_ratio           5169 non-null   float64\n",
      " 4   word_overlap_count     5169 non-null   int64  \n",
      " 5   bigram_overlap_count   5169 non-null   int64  \n",
      " 6   trigram_overlap_count  5169 non-null   int64  \n",
      " 7   quotes_count           5169 non-null   int64  \n",
      " 8   content_model250_avg   5169 non-null   float64\n",
      " 9   wording_model250_avg   5169 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 444.2 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1347\n",
      "[LightGBM] [Info] Number of data points in the train set: 5169, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.028040\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 0.720014\n",
      "[20]\ttrain's rmse: 0.580034\n",
      "[30]\ttrain's rmse: 0.515567\n",
      "[40]\ttrain's rmse: 0.488607\n",
      "[50]\ttrain's rmse: 0.477595\n",
      "[60]\ttrain's rmse: 0.473217\n",
      "[70]\ttrain's rmse: 0.471818\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's rmse: 0.472405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttrain's rmse: 0.47288\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttrain's rmse: 0.471815\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6062 entries, 1 to 7164\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   summary_length         6062 non-null   int64  \n",
      " 1   splling_err_num        6062 non-null   int64  \n",
      " 2   prompt_length          6062 non-null   int64  \n",
      " 3   length_ratio           6062 non-null   float64\n",
      " 4   word_overlap_count     6062 non-null   int64  \n",
      " 5   bigram_overlap_count   6062 non-null   int64  \n",
      " 6   trigram_overlap_count  6062 non-null   int64  \n",
      " 7   quotes_count           6062 non-null   int64  \n",
      " 8   content_model250_avg   6062 non-null   float64\n",
      " 9   wording_model250_avg   6062 non-null   float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 521.0 KB\n",
      "None\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1401\n",
      "[LightGBM] [Info] Number of data points in the train set: 6062, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.168933\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's rmse: 1.03187\n",
      "[20]\ttrain's rmse: 0.877235\n",
      "[30]\ttrain's rmse: 0.794868\n",
      "[40]\ttrain's rmse: 0.751032\n",
      "[50]\ttrain's rmse: 0.731275\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttrain's rmse: 0.719256\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttrain's rmse: 0.710245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttrain's rmse: 0.703768\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttrain's rmse: 0.70046\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttrain's rmse: 0.697925\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[110]\ttrain's rmse: 0.697334\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttrain's rmse: 0.696655\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttrain's rmse: 0.696073\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttrain's rmse: 0.69539\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttrain's rmse: 0.6951\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[160]\ttrain's rmse: 0.694697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[170]\ttrain's rmse: 0.694472\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[180]\ttrain's rmse: 0.694439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[190]\ttrain's rmse: 0.694226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttrain's rmse: 0.694517\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[210]\ttrain's rmse: 0.694478\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[220]\ttrain's rmse: 0.694928\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttrain's rmse: 0.694206\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for target in targets:\n",
    "    models = []\n",
    "    \n",
    "    for fold in [0,1,2,3]:\n",
    "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
    "        \n",
    "        print(X_train_cv.info())\n",
    "        \n",
    "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
    "\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
    "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
    "        \n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': 42,\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.045,\n",
    "            'max_depth': 3,\n",
    "            'lambda_l1': 0.1,\n",
    "#             'lambda_l2': 0.01\n",
    "        }\n",
    "        \n",
    "\n",
    "        evaluation_results = {}\n",
    "        model = lgb.train(\n",
    "          params,\n",
    "          num_boost_round=10000,\n",
    "            #categorical_feature = categorical_features,\n",
    "          valid_names=['train', 'valid'],\n",
    "          train_set=dtrain,\n",
    "          valid_sets=[dval],\n",
    "            \n",
    "#           early_stopping_rounds=10,  # Stop if no improvement in 10 rounds\n",
    "#           verbose_eval=10  # Print progress every 10 rounds\n",
    "            \n",
    "          callbacks=[\n",
    "              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
    "              lgb.log_evaluation(10),\n",
    "              lgb.callback.record_evaluation(evaluation_results)\n",
    "            ],\n",
    "        )\n",
    "        models.append(model)\n",
    "\n",
    "    \n",
    "    model_dict[target] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48a2a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_rmse : 0.43729095808875873\n",
      "wording_rmse : 0.562393929440772\n",
      "mcrmse : 0.4998424437647654\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "rmses = []\n",
    "\n",
    "preds_target = {}\n",
    "\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    ids = []\n",
    "    \n",
    "    folds = [0,1,2,3]\n",
    "    \n",
    "    for fold, model in zip(folds, models):\n",
    "        fold_ids = train[train[\"fold\"] == fold].student_id.values\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "\n",
    "        trues.extend(y_eval_cv)\n",
    "        preds.extend(pred)\n",
    "        ids.extend(fold_ids)\n",
    "        \n",
    "    preds_target[target] = preds\n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    print(f\"{target}_rmse : {rmse}\")\n",
    "    rmses = rmses + [rmse]\n",
    "\n",
    "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554e7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e11abe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_rmse : 0.4298522117128822\n",
    "wording_rmse : 0.5883296879464759\n",
    "mcrmse : 0.5090909498296791\n",
    "\n",
    "\n",
    "# content_rmse : 0.4314174437930952\n",
    "# wording_rmse : 0.5666001367824579\n",
    "# mcrmse : 0.49900879028777656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a354d3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7165"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_target['wording'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee718e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9256882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd505b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ff5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf3442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4566ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a01e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef95277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129d83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994ef8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d22537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036b433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa5bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d7e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_df = pd.DataFrame({\n",
    "    'student_id': ids,\n",
    "    'content_pred': preds_target['content'],\n",
    "    'wording_pred': preds_target['wording']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd992b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_df.to_csv(\"../data/raw/pseudo_lgbm1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af350f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14253bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_rmse_content(params):    \n",
    "    \n",
    "    for index, val in enumerate(params.keys()):\n",
    "        if index == 0:            \n",
    "            preds = params[val]*oofs[0][['content_pred']].values\n",
    "        else:\n",
    "            preds += params[val]*oofs[index][['content_pred']].values\n",
    "    \n",
    "    param_sum = 0\n",
    "    for key, val in params.items():\n",
    "        param_sum += val\n",
    "\n",
    "    preds = preds/param_sum\n",
    "    \n",
    "    score, _ = get_score(true_labels_content, preds, single=True)\n",
    "    return score\n",
    "\n",
    "\n",
    "def reduce_rmse_wording(params):    \n",
    "    \n",
    "    for index, val in enumerate(params.keys()):\n",
    "        if index == 0:            \n",
    "            preds = params[val]*oofs[0][['wording_pred']].values\n",
    "        else:\n",
    "            preds += params[val]*oofs[index][['wording_pred']].values\n",
    "    \n",
    "    param_sum = 0\n",
    "    for key, val in params.items():\n",
    "        param_sum += val\n",
    "\n",
    "    preds = preds/param_sum\n",
    "    \n",
    "    score, _ = get_score(true_labels_wording, preds, single=True)\n",
    "    return score\n",
    "    \n",
    "\n",
    "\n",
    "def objective_content(trial):\n",
    "    \n",
    "    params = {}    \n",
    "    for i in range(len(oofs)):\n",
    "        params[f\"w{i+1}\"] = trial.suggest_float(f'w{i+1}', 0, 1) \n",
    "        \n",
    "        \n",
    "# #     params['w1'] = trial.suggest_float(f'w1', 0, 1)\n",
    "#     params['w1'] = 0.0\n",
    "# #     params['w2'] = trial.suggest_float(f'w2', 0, 1)\n",
    "#     params['w2'] = 0.2751292481676879\n",
    "# #     params['w3'] = trial.suggest_float(f'w3', 0, 1)\n",
    "#     params['w3'] = 0.9334223120116154\n",
    "# #     params['w4'] = trial.suggest_float(f'w4', 0, 1)\n",
    "#     params['w4'] = 0.33590012439835765\n",
    "# #     params['w5'] = trial.suggest_float(f'w5', 0, 1)\n",
    "#     params['w5'] = 0.9167395356124376\n",
    "#     params['w6'] = trial.suggest_float(f'w6', 0, 1)\n",
    "#     params['w6'] = 0.06456631090298333\n",
    "        \n",
    "        \n",
    "        \n",
    "    score = reduce_rmse_content(params)\n",
    "    return score\n",
    "\n",
    "\n",
    "def objective_wording(trial):\n",
    "    params = {}    \n",
    "    for i in range(len(oofs)):\n",
    "        params[f\"w{i+1}\"] = trial.suggest_float(f'w{i+1}', 0, 1) \n",
    "    \n",
    "    \n",
    "    \n",
    "# #     params['w1'] = trial.suggest_float(f'w1', 0, 1)\n",
    "#     params['w1'] = 0.467454419562916\n",
    "# #     params['w2'] = trial.suggest_float(f'w2', 0, 1)\n",
    "#     params['w2'] = 0.0\n",
    "# #     params['w3'] = trial.suggest_float(f'w3', 0, 1)\n",
    "#     params['w3'] = 0.0\n",
    "# #     params['w4'] = trial.suggest_float(f'w4', 0, 1)\n",
    "#     params['w4'] = 0.0\n",
    "# #     params['w5'] = trial.suggest_float(f'w5', 0, 1)\n",
    "#     params['w5'] = 0.24793402911254775\n",
    "# #     params['w6'] = trial.suggest_float(f'w6', 0, 1)\n",
    "#     params['w6'] = 0.872806341843549\n",
    "    \n",
    "\n",
    "    \n",
    "    score = reduce_rmse_wording(params)\n",
    "    return score\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c988ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_content, n_trials=500)\n",
    "best_params_content = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_content # 0.0.4350322004265345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639ff51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_wording, n_trials=500)\n",
    "best_params_wording = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80feb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_wording # 0.0.5824519396100762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40458694",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = 0.43503616854966076\n",
    "wording = 0.5813420492103132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2db268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((content + wording)/2, f\"[content - {content}, wording - {wording}]\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oofs # 0.5323537777575318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8eeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081be0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db70f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c7247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637814c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0749ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26101a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648a256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4e082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6907d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = {\n",
    "    \"content\": {\n",
    "        'model208': 0.014894157748461517,\n",
    "        'model210': 0.024798218285980337,\n",
    "        'model222': 0.3683565615916879,\n",
    "        'model223': 0.07440796563094199,\n",
    "        'model301': 0.26009101940467266,\n",
    "        'model303': 0.035186623400637024,\n",
    "        'model304': 0.03131238078272683,\n",
    "        'model228': 0.27593695225248327,\n",
    "        'model229': 0.9533872030382488,\n",
    "        \n",
    "    },\n",
    "    \n",
    "    \"wording\": {\n",
    "        'model208': 0.0520672559265657,\n",
    "        'model210': 0.019115888342385444,\n",
    "        'model222': 0.0257670812178082,\n",
    "        'model223': 0.06963802230475018,\n",
    "        'model301': 0.004504811515739459,\n",
    "        'model303': 0.42283927332769894,\n",
    "        'model304': 0.050441060713579226,\n",
    "        'model228': 0.9768371762718951,\n",
    "        'model229': 0.9179471545026996,\n",
    "    }    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162034b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "content_final = None\n",
    "\n",
    "for col in ['content']:\n",
    "    w_ = best_weights[col]\n",
    "    for idx, (model_key, model_wt) in enumerate(w_.items()):\n",
    "        print(model_key, model_wt)\n",
    "        if idx == 0:\n",
    "            content_final = oofs[idx]['content_pred'].values * model_wt\n",
    "        else:\n",
    "            content_final += oofs[idx]['content_pred'].values * model_wt\n",
    "    content_final = content_final/np.sum(list(w_.values()))\n",
    "    print(np.sum(list(w_.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6244ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wording_final = None\n",
    "\n",
    "for col in ['wording']:\n",
    "    w_ = best_weights[col]\n",
    "    for idx, (model_key, model_wt) in enumerate(w_.items()):\n",
    "        print(model_key, model_wt)\n",
    "        if idx == 0:\n",
    "            wording_final = oofs[idx]['wording_pred'].values* model_wt\n",
    "        else:\n",
    "            wording_final += oofs[idx]['wording_pred'].values * model_wt\n",
    "    wording_final = wording_final/np.sum(list(w_.values()))\n",
    "    print(np.sum(list(w_.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84dd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oof_df = oofs[0].copy()\n",
    "\n",
    "true_labels_oof = final_oof_df[['content_gt', 'wording_gt']].values\n",
    "final_oof_df['content_pred'] = content_final\n",
    "final_oof_df['wording_pred'] = wording_final\n",
    "predictions_oof = final_oof_df[['content_pred', 'wording_pred']].values \n",
    "\n",
    "score, scores = get_score(true_labels_oof, predictions_oof)\n",
    "print(score, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98452f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oof_df.to_csv(\"../data/raw/pseudo2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db0ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7db22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c26f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb66b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eba733",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare v1 pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e82058",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = {\n",
    "    \"content\": {\n",
    "        'model208': 0.021420427641406517,\n",
    "        'model210': 0.17377306975618464,\n",
    "        'model222': 0.6944174081358903,\n",
    "        'model223': 0.2540676804844625,\n",
    "        'model301': 0.6028460120908795,\n",
    "        'model303': 0.027908605704995954,\n",
    "    },\n",
    "    \n",
    "    \"wording\": {\n",
    "        'model208': 0.467454419562916,\n",
    "        'model210': 0.0,\n",
    "        'model222': 0.0,\n",
    "        'model223': 0.0,\n",
    "        'model301': 0.24793402911254775,\n",
    "        'model303': 0.872806341843549,\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_final = None\n",
    "\n",
    "for col in ['content']:\n",
    "    w_ = best_weights[col]\n",
    "    for idx, (model_key, model_wt) in enumerate(w_.items()):\n",
    "        print(model_key, model_wt)\n",
    "        if idx == 0:\n",
    "            content_final = oofs[idx]['content_pred'].values * model_wt\n",
    "        else:\n",
    "            content_final += oofs[idx]['content_pred'].values * model_wt\n",
    "    content_final = content_final/np.sum(list(w_.values()))\n",
    "    print(np.sum(list(w_.values())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d09013",
   "metadata": {},
   "outputs": [],
   "source": [
    "wording_final = None\n",
    "\n",
    "for col in ['wording']:\n",
    "    w_ = best_weights[col]\n",
    "    for idx, (model_key, model_wt) in enumerate(w_.items()):\n",
    "        print(model_key, model_wt)\n",
    "        if idx == 0:\n",
    "            wording_final = oofs[idx]['wording_pred'].values* model_wt\n",
    "        else:\n",
    "            wording_final += oofs[idx]['wording_pred'].values * model_wt\n",
    "    wording_final = wording_final/np.sum(list(w_.values()))\n",
    "    print(np.sum(list(w_.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c686ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oof_df = oofs[0].copy()\n",
    "\n",
    "true_labels_oof = final_oof_df[['content_gt', 'wording_gt']].values\n",
    "final_oof_df['content_pred'] = content_final\n",
    "final_oof_df['wording_pred'] = wording_final\n",
    "predictions_oof = final_oof_df[['content_pred', 'wording_pred']].values \n",
    "\n",
    "score, scores = get_score(true_labels_oof, predictions_oof)\n",
    "print(score, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d53370",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oof_df.to_csv(\"pseudo1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6ed64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf74237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(true_labels_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af804ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_columns = ['content', 'wording']\n",
    "# oof_final[target_columns] = 0\n",
    "\n",
    "# for col in target_columns:\n",
    "#     w_ = best_weights[col]\n",
    "#     for fn, w in w_.items():\n",
    "#         oof_final[col] += oof_final[col+'_'+fn] * w\n",
    "#     oof_final[col] = oof_final[col]/np.sum(list(w_.values()))\n",
    "    \n",
    "    \n",
    "# oof_final = oof_final[['student_id'] + target_columns]\n",
    "# # submission[target_columns] = submission[target_columns] .clip(1, 5)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fb628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ebd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd132a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef84f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "12302f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/rohits/pv1/commonlit/data/raw/train_folds_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8e944ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With one member trimming beef in a cannery, and another working in a sausage factory, the family had a first-hand knowledge of the great majority of Packingtown swindles. For it was the custom, as they found, whenever meat was so spoiled that it could not be used for anything else, either to can it or else to chop it up into sausage. With what had been told them by Jonas, who had worked in the pickle rooms, they could now study the whole of the spoiled-meat industry on the inside, and read a new and grim meaning into that old Packingtown jest—that they use everything of the pig except the squeal. \\r\\nJonas had told them how the meat that was taken out of pickle would often be found sour, and how they would rub it up with soda to take away the smell, and sell it to be eaten on free-lunch counters; also of all the miracles of chemistry which they performed, giving to any sort of meat, fresh or salted, whole or chopped, any color and any flavor and any odor they chose. In the pickling of hams they had an ingenious apparatus, by which they saved time and increased the capacity of the plant—a machine consisting of a hollow needle attached to a pump; by plunging this needle into the meat and working with his foot, a man could fill a ham with pickle in a few seconds. And yet, in spite of this, there would be hams found spoiled, some of them with an odor so bad that a man could hardly bear to be in the room with them. To pump into these the packers had a second and much stronger pickle which destroyed the odor—a process known to the workers as “giving them thirty per cent.” Also, after the hams had been smoked, there would be found some that had gone to the bad. Formerly these had been sold as “Number Three Grade,” but later on some ingenious person had hit upon a new device, and now they would extract the bone, about which the bad part generally lay, and insert in the hole a white-hot iron. After this invention there was no longer Number One, Two, and Three Grade—there was only Number One Grade. The packers were always originating such schemes—they had what they called “boneless hams,” which were all the odds and ends of pork stuffed into casings; and “California hams,” which were the shoulders, with big knuckle joints, and nearly all the meat cut out; and fancy “skinned hams,” which were made of the oldest hogs, whose skins were so heavy and coarse that no one would buy them—that is, until they had been cooked and chopped fine and labeled “head cheese!” \\r\\nIt was only when the whole ham was spoiled that it came into the department of Elzbieta. Cut up by the two-thousand-revolutions- a-minute flyers, and mixed with half a ton of other meat, no odor that ever was in a ham could make any difference. There was never the least attention paid to what was cut up for sausage; there would come all the way back from Europe old sausage that had been rejected, and that was moldy and white – it would be dosed with borax and glycerin, and dumped into the hoppers, and made over again for home consumption. \\r\\nThere would be meat that had tumbled out on the floor, in the dirt and sawdust, where the workers had tramped and spit uncounted billions of consumption germs. There would be meat stored in great piles in rooms; and the water from leaky roofs would drip over it, and thousands of rats would race about on it. It was too dark in these storage places to see well, but a man could run his hand over these piles of meat and sweep off handfuls of the dried dung of rats. These rats were nuisances, and the packers would put poisoned bread out for them; they would die, and then rats, bread, and meat would go into the hoppers together. This is no fairy story and no joke; the meat would be shoveled into carts, and the man who did the shoveling would not trouble to lift out a rat even when he saw one – there were things that went into the sausage in comparison with which a poisoned rat was a tidbit. \\r\\nThere was no place for the men to wash their hands before they ate their dinner, and so they made a practice of washing them in the water that was to be ladled into the sausage. There were the butt-ends of smoked meat, and the scraps of corned beef, and all the odds and ends of the waste of the plants, that would be dumped into old barrels in the cellar and left there. Under the system of rigid economy which the packers enforced, there were some jobs that it only paid to do once in a long time, and among these was the cleaning out of the waste barrels. Every spring they did it; and in the barrels would be dirt and rust and old nails and stale water – and cartload after cartload of it would be taken up and dumped into the hoppers with fresh meat, and sent out to the public\\'s breakfast. Some of it they would make into \"smoked\" sausage – but as the smoking took time, and was therefore expensive, they would call upon their chemistry department, and preserve it with borax and color it with gelatin to make it brown. All of their sausage came out of the same bowl, but when they came to wrap it they would stamp some of it \"special,\" and for this they would charge two cents more a pound.'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = train.loc[train.fold == 2]\n",
    "fold['prompt_text'].unique()[0] # 604, 550, 966, 596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "90f862b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['student_id', 'prompt_id', 'text', 'content', 'wording', 'fold'], dtype='object')"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c6af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42dda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ceed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfdc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = train['text'][300]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def clean_summary(summary):\n",
    "    for word in summary.split():\n",
    "        if word.lower() in contractions:\n",
    "            summary = summary.replace(word, contractions[word.lower()])\n",
    "    # Add space after punctuations\n",
    "    clean_summary = summary.replace(\"\\n\", \"[BR]\")\n",
    "    # Remove HTML tags using BeautifulSoup\n",
    "    clean_summary = BeautifulSoup(clean_summary, \"html.parser\").get_text()\n",
    "    # Remove special characters and non-printable characters\n",
    "    clean_summary = re.sub(r'[^A-Za-z0-9\\s]', ' ', clean_summary)\n",
    "    # Remove extra spaces and newlines\n",
    "    clean_summary = re.sub(r'\\s+', ' ', clean_summary).strip()\n",
    "    \n",
    "    return clean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e166fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_summary(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00141abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6fa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
